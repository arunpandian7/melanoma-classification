{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7oIOWifkMtqP",
    "outputId": "0600c26d-52e8-4f8c-d7df-f7c738d7e935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  5115  100  5115    0     0  71041      0 --:--:-- --:--:-- --:--:-- 71041\n",
      "Updating... This may take around 2 minutes.\n",
      "Updating TPU runtime to pytorch-nightly ...\n",
      "Collecting cloud-tpu-client\n",
      "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from cloud-tpu-client) (4.1.3)\n",
      "Collecting google-api-python-client==1.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (4.6)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
      "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.2)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.16.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.1.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (49.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.52.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.4)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
      "Uninstalling torch-1.6.0+cu101:\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
      "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
      "  Found existing installation: google-api-python-client 1.7.12\n",
      "    Uninstalling google-api-python-client-1.7.12:\n",
      "      Successfully uninstalled google-api-python-client-1.7.12\n",
      "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
      "Done updating TPU runtime\n",
      "  Successfully uninstalled torch-1.6.0+cu101\n",
      "Uninstalling torchvision-0.7.0+cu101:\n",
      "  Successfully uninstalled torchvision-0.7.0+cu101\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly-cp36-cp36m-linux_x86_64.whl...\n",
      "- [1 files][110.9 MiB/110.9 MiB]                                                \n",
      "Operation completed over 1 objects/110.9 MiB.                                    \n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly-cp36-cp36m-linux_x86_64.whl...\n",
      "\\ [1 files][127.3 MiB/127.3 MiB]                                                \n",
      "Operation completed over 1 objects/127.3 MiB.                                    \n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly-cp36-cp36m-linux_x86_64.whl...\n",
      "/ [1 files][  2.4 MiB/  2.4 MiB]                                                \n",
      "Operation completed over 1 objects/2.4 MiB.                                      \n",
      "Processing ./torch-nightly-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (3.7.4.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly) (1.18.5)\n",
      "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.7.0a0+8864148\n",
      "Processing ./torch_xla-nightly-cp36-cp36m-linux_x86_64.whl\n",
      "Installing collected packages: torch-xla\n",
      "Successfully installed torch-xla-1.6+7da4922\n",
      "Processing ./torchvision-nightly-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (7.0.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly) (1.7.0a0+8864148)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly) (3.7.4.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.8.0a0+27278ec\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  libomp5\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 234 kB of archives.\n",
      "After this operation, 774 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
      "Fetched 234 kB in 1s (362 kB/s)\n",
      "Selecting previously unselected package libomp5:amd64.\n",
      "(Reading database ... 144487 files and directories currently installed.)\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "YFNme-FMMtqY",
    "outputId": "238d36a3-ac00-42cc-e0e0-d7dddd2bfd60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting git+https://github.com/abhishekkrthakur/wtfml\n",
      "  Cloning https://github.com/abhishekkrthakur/wtfml to /tmp/pip-req-build-9xkne4am\n",
      "  Running command git clone -q https://github.com/abhishekkrthakur/wtfml /tmp/pip-req-build-9xkne4am\n",
      "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.6/dist-packages (from wtfml==0.0.4) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->wtfml==0.0.4) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->wtfml==0.0.4) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.1->wtfml==0.0.4) (1.18.5)\n",
      "Building wheels for collected packages: wtfml\n",
      "  Building wheel for wtfml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wtfml: filename=wtfml-0.0.4-cp36-none-any.whl size=12538 sha256=8db1c44af07e7e877a2dda9fdd3a5fb9d1968247656bca0e58b03d97a8f448e1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uftkgvud/wheels/a5/67/ee/67208960d01000b054678b0bff5e5f91995651fe354abbc989\n",
      "Successfully built wtfml\n",
      "Installing collected packages: wtfml\n",
      "Successfully installed wtfml-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -q efficientnet_pytorch       # Convolutional Neural Net from Google Research\n",
    "!pip install git+https://github.com/abhishekkrthakur/wtfml #Abishek Takur's Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4x589NGkM3QU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the API Key JSON file from Kaggle Account Settings\n",
    "os.environ['KAGGLE_USERNAME'] = \"XXXXXX\" \n",
    "os.environ['KAGGLE_KEY'] = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QghTFEbBNYgp"
   },
   "outputs": [],
   "source": [
    "!mkdir input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "utNaBrhuMvU2",
    "outputId": "77a9ffc8-98db-45f4-9863-86857797a686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading melanoma-efficientnet-inference.zip to /content\n",
      "100% 2.88G/2.88G [00:30<00:00, 65.6MB/s]\n",
      "100% 2.88G/2.88G [00:31<00:00, 99.6MB/s]\n",
      "Downloading melanoma-external-malignant-256.zip to /content\n",
      " 99% 1.00G/1.01G [00:15<00:00, 44.6MB/s]\n",
      "100% 1.01G/1.01G [00:15<00:00, 70.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d nroman/melanoma-external-malignant-256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f3Vpc5kO2Yk"
   },
   "outputs": [],
   "source": [
    "!unzip -q melanoma-efficientnet-inference.zip \n",
    "!unzip -q melanoma-external-malignant-256.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwedZOy2PTpc"
   },
   "outputs": [],
   "source": [
    "!rm -rf *.pth *.zip *.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "j10xcXyMMtqg",
    "outputId": "0e6b46e1-3204-49ef-8ade-e5c155ccb199"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAABECAYAAADHuCM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABqUlEQVR4nO3YIU7EUBSG0fcIgaBwGBIUCUEzAo3AsAZs2QGLmcWwgrGEHRB2cTEIBgKj2v7TnOPaZ+41X/raq6oBpDiYewCA70QJiCJKQBRRAqKIEhDl8OeL3vvQWhtaa+3k7Orm+PR88qGm8vFwMfcIo3p9ep57hNG8b17mHmFU97fXc48wqqPLu/7X2a8vpapaV9WqqlZLDhKQyfUNiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAoogREESUgiigBUUQJiCJKQBRRAqKIEhBFlIAovaq2X/Q+tNaGr8e3qnqcfKqJ9N6HqlrPPcdY7Le/lrzbLr+itHXY+6aqVhPOMyn77bcl77fk3XZxfQOiiBIQZVeUln6ntd9+W/J+S97tX//+UwKYmusbEOUTEANKp2qRrXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sys\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image \n",
    "import gc\n",
    "import time\n",
    "import datetime as dt\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#Data Tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg # Validate Images\n",
    "\n",
    "#Sci-kit learn tools\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#PyTorch \n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import LongTensor, FloatTensor\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.optim.lr_scheduler as ReduceLROnPlateau\n",
    "from wtfml.utils import EarlyStopping #Abishek's Library\n",
    "\n",
    "\n",
    "\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "#TPU Stuffs\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    _xla_available = True\n",
    "except ImportError:\n",
    "    _xla_available = False\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "\n",
    "    _apex_available = True\n",
    "except ImportError:\n",
    "    _apex_available = False\n",
    "\n",
    "\n",
    "#Augmentations\n",
    "from albumentations import (ToFloat, Normalize, HorizontalFlip, Compose, Resize, ShiftScaleRotate,\n",
    "                          VerticalFlip, RandomBrightnessContrast, RandomContrast, HueSaturationValue, Blur, GaussNoise, Rotate, Cutout)\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchvision.models import resnet34, resnet50\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "color_palette = ['#102542', '#f87060', '#cdd7d6', '#b3a394', '#f9dbbd']\n",
    "sns.palplot(sns.color_palette(color_palette))\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.despine(left=True, bottom=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i31wn5vLMtqm"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 7237):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "N7bce5wwMtsp",
    "outputId": "76f5972c-d417-485f-d05c-e8ab0a8e4312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Len: 37648 \n",
      "Test_Len:10982\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/train_processed.csv')\n",
    "test_df = pd.read_csv('./data/test_processed.csv')\n",
    "\n",
    "\n",
    "to_drop = ['path_dicom', 'path_jpeg', 'diagnosis']\n",
    "\n",
    "for drop in to_drop:\n",
    "    if drop in train_df.columns:\n",
    "        train_df.drop([drop], axis=1, inplace=True)\n",
    "\n",
    "roman_train = pd.read_csv('train_concat.csv') #Roman's Processed Data\n",
    "\n",
    "roman_train['patient_id'] = roman_train['patient_id'].fillna(0)\n",
    "\n",
    "\n",
    "to_encode = ['sex', 'anatom_site_general_challenge']\n",
    "encoded_all = []\n",
    "\n",
    "roman_train[to_encode[0]] = roman_train[to_encode[0]].astype(str)\n",
    "roman_train[to_encode[1]] = roman_train[to_encode[1]].astype(str)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in to_encode:\n",
    "    encoded = label_encoder.fit_transform(roman_train[column])\n",
    "    encoded_all.append(encoded)\n",
    "\n",
    "roman_train[to_encode[0]] = encoded_all[0]\n",
    "roman_train[to_encode[1]] = encoded_all[1]\n",
    "\n",
    "col_list = list(train_df.columns)\n",
    "col_list.remove('benign_malignant')\n",
    "roman_train.columns = col_list\n",
    "\n",
    "\n",
    "common_images = train_df['dcm_name'].unique()\n",
    "new_data = roman_train[~roman_train['dcm_name'].isin(common_images)]\n",
    "\n",
    "train_df = pd.concat([train_df, new_data], axis=0)\n",
    "\n",
    "\n",
    "for drop in to_drop:\n",
    "    if drop in test_df.columns:\n",
    "        test_df.drop([drop], axis=1, inplace=True)\n",
    "    \n",
    "path_train = './train/train/'\n",
    "path_test = './test/test/'\n",
    "\n",
    "train_df['path_jpg'] = path_train + train_df['dcm_name']+'.jpg'\n",
    "test_df['path_jpg'] = path_test + test_df['dcm_name'] + '.jpg'\n",
    "\n",
    "train_df['age'] = train_df['age'].fillna(-1)\n",
    "\n",
    "normalized_train = preprocessing.normalize(train_df[['sex', 'age', 'anatomy']])\n",
    "normalized_test = preprocessing.normalize(test_df[['sex', 'age', 'anatomy']])\n",
    "\n",
    "train_df['sex'] = normalized_train[:, 0]\n",
    "train_df['age'] = normalized_train[:, 1]\n",
    "train_df['anatomy'] = normalized_train[:, 2]\n",
    "\n",
    "test_df['sex'] = normalized_test[:, 0]\n",
    "test_df['age'] = normalized_test[:, 1]\n",
    "test_df['anatomy'] = normalized_test[:, 2]\n",
    "\n",
    "print(f'Train Len: {len(train_df)} \\nTest_Len:{len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LWWvyfwMtss"
   },
   "outputs": [],
   "source": [
    "vertical_flip = 0.5\n",
    "horizontal_flip = 0.5\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "\n",
    "columns = ['sex', 'age', 'anatomy']\n",
    "no_columns = 3 \n",
    "output_size = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O3pHAw1xMtsw",
    "outputId": "691cabd2-de21-432d-8ec0-dd13b219d62b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02221674, 0.9997532 , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_df.iloc[0][columns].values, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Lq_3pcTMtsz"
   },
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, vertical_flip, horizontal_flip, is_train=True, is_valid=False, is_test=False):\n",
    "        self.dataframe, self.is_train, self.is_valid= dataframe, is_train, is_valid\n",
    "        self.vertical_flip, self.horizontal_flip = vertical_flip, horizontal_flip\n",
    "        \n",
    "        if is_train or is_test :\n",
    "            self.transform = Compose([Normalize(mean = (0.485, 0.456, 0.406),\n",
    "                                                std = (0.229, 0.224, 0.225), \n",
    "                                                max_pixel_value=255.0, \n",
    "                                                always_apply=True),\n",
    "                                      HorizontalFlip(p = self.horizontal_flip),\n",
    "                                      VerticalFlip(p = self.vertical_flip),\n",
    "                                      HueSaturationValue(\n",
    "                                          sat_shift_limit=[0.7, 1.3], \n",
    "                                          hue_shift_limit=[-0.1, 0.1]),\n",
    "                                      RandomBrightnessContrast(brightness_limit=[0.7, 1.3],\n",
    "                                                               contrast_limit= [0.7, 1.3]),\n",
    "                                      ToTensor()])\n",
    "        else:\n",
    "            self.transform = Compose([Normalize(mean = (0.485, 0.456, 0.406), \n",
    "                                                std = (0.229, 0.224, 0.225), \n",
    "                                                max_pixel_value=255.0,\n",
    "                                                always_apply=True), \n",
    "                                      ToTensor()])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.dataframe['path_jpg'][index]\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        csv_data = np.array(self.dataframe.iloc[index][['sex', 'age', 'anatomy']].values, dtype=np.float32)\n",
    "        \n",
    "        image = self.transform(image=image)\n",
    "        \n",
    "        image = image['image']\n",
    "        \n",
    "        if self.is_train or self.is_valid:\n",
    "            return (image, csv_data), self.dataframe['target'][index]\n",
    "        else:\n",
    "            return(image, csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9H-uQrQMts4"
   },
   "outputs": [],
   "source": [
    "class CustomLoader:\n",
    "    def __init__(self, dataframe, is_train = True, is_valid = False, is_test = False):\n",
    "        \"\"\"\n",
    "        :param image_paths: list of paths to images\n",
    "        :param targets: numpy array\n",
    "        :param resize: tuple or None\n",
    "        :param augmentations: albumentations augmentations\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        if is_train:\n",
    "            self.dataset = MelanomaDataset(self.dataframe, vertical_flip=vertical_flip, horizontal_flip=horizontal_flip, \n",
    "                                is_train=True, is_valid=False, is_test=False)\n",
    "\n",
    "        elif is_valid:\n",
    "            self.dataset = MelanomaDataset(self.dataframe, vertical_flip=vertical_flip, horizontal_flip=horizontal_flip, \n",
    "                                is_train=False, is_valid=True, is_test=False)\n",
    "        elif is_test:\n",
    "            self.dataset = MelanomaDataset(self.dataframe, vertical_flip = vertical_flip, horizontal_flip=horizontal_flip,\n",
    "                                          is_train=False, is_valid=False, is_test=True)\n",
    "\n",
    "\n",
    "    def fetch(self, batch_size, num_workers, drop_last=False, shuffle=True, tpu=False):\n",
    "        \"\"\"\n",
    "        :param batch_size: batch size\n",
    "        :param num_workers: number of processes to use\n",
    "        :param drop_last: drop the last batch?\n",
    "        :param shuffle: True/False\n",
    "        :param tpu: True/False, to use tpu or not\n",
    "        \"\"\"\n",
    "        sampler = None\n",
    "        if tpu:\n",
    "            sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                self.dataset,\n",
    "                num_replicas=xm.xrt_world_size(),\n",
    "                rank=xm.get_ordinal(),\n",
    "                shuffle=shuffle,\n",
    "            )\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            drop_last=drop_last,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "        return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N613sxGDMts8"
   },
   "outputs": [],
   "source": [
    "class EfficientModel(nn.Module):\n",
    "    def __init__(self, output_size, no_columns, net_type='b2'):\n",
    "        super().__init__()\n",
    "        self.net_type, self.no_columns = net_type, no_columns\n",
    "        \n",
    "        if net_type not in ['b2', 'b4', 'b7']:\n",
    "            raise Exception('Sorry, it is an unsupported EfficientNet Type. Only b2, b4, b7 are valid.')\n",
    "        \n",
    "        self.features = EfficientNet.from_pretrained('efficientnet-'+net_type)\n",
    "        \n",
    "        self.csv = nn.Sequential(nn.Linear(self.no_columns, 250),\n",
    "                                nn.BatchNorm1d(250),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.2),\n",
    "                                nn.Linear(250, 250),\n",
    "                                nn.BatchNorm1d(250),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.2))\n",
    "        if net_type=='b4':\n",
    "            self.classification = nn.Sequential(nn.Linear(1792+250, output_size))\n",
    "        elif net_type == 'b2':\n",
    "            self.classification = nn.Sequential(nn.Linear(1408+250, output_size))\n",
    "        elif net_type == 'b7':\n",
    "            self.classification = nn.Sequential(nn.Linear(2560+250, output_size))\n",
    "        \n",
    "    def forward(self, input_data, prints=False):\n",
    "        (image, csv_data) = input_data\n",
    "        if prints:print('Input Image Shape:', image.shape, '\\n' + \n",
    "                       'Input csv_data shape:', csv_data.shape)\n",
    "        \n",
    "        image = self.features.extract_features(image)\n",
    "        \n",
    "        if prints:print('Feature Image Shape:', image.shape)\n",
    "            \n",
    "        if self.net_type=='b4': image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1792)\n",
    "        elif self.net_type=='b2': image= F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1408)\n",
    "        else: image = F.avg_pool2d(image, image.size()[2:].reshape(-1, 2560))\n",
    "            \n",
    "        if prints: print('Image Reshaped Shape:', image.shape)\n",
    "        \n",
    "        csv_data = self.csv(csv_data)\n",
    "        \n",
    "        if prints: print('CSV Data:', csv_data.shape)\n",
    "            \n",
    "        image_csv_data = torch.cat((image, csv_data), dim=1)\n",
    "        \n",
    "        out = self.classification(image_csv_data)\n",
    "        \n",
    "        if prints: print('Out Shape:', out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "c_lSrKr97HEG",
    "outputId": "8a405762-8d20-487e-cfa4-68c38a571a9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcm_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>anatomy</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "      <th>path_jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>./train/train/ISIC_2637011.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>0.110432</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>./train/train/ISIC_0015719.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.019996</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>./train/train/ISIC_0052212.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>./train/train/ISIC_0068279.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995893</td>\n",
       "      <td>0.090536</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "      <td>./train/train/ISIC_0074268.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dcm_name          ID  ...  target                        path_jpg\n",
       "0  ISIC_2637011  IP_7279968  ...       0  ./train/train/ISIC_2637011.jpg\n",
       "1  ISIC_0015719  IP_3075186  ...       0  ./train/train/ISIC_0015719.jpg\n",
       "2  ISIC_0052212  IP_2842074  ...       0  ./train/train/ISIC_0052212.jpg\n",
       "3  ISIC_0068279  IP_6890425  ...       0  ./train/train/ISIC_0068279.jpg\n",
       "4  ISIC_0074268  IP_8723313  ...       0  ./train/train/ISIC_0074268.jpg\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "98aa2a8d041542c3855342e544915738",
      "a46209433a4d42f786a3dde350d313eb",
      "df009758bce245d88d569baa422a3023",
      "11a0ea6cf3ed48d9a6c948490c2822c6",
      "3478c4a8631e4496a523e699b11cc3d0",
      "2d0da7ff8daa48a5bb8abc840eaba213",
      "19d07b0aa94c4a06a6cb9a2fc04db440",
      "9fefdb48d75a47389e6bb6e6f4034437",
      "4b78fe2f88ea4c499a75ecfa8c5cd0aa",
      "be0f0144424e497e8e4301a0a5a9d541",
      "6a335bc975cc4e5f9cc5f307720900b9",
      "43ad1b6892d24065baf27f89ba931a16",
      "f5a40e7df69a4915922c93f4e43e0cfb",
      "e130e44a53304705a80ab7ec42cf0f0f",
      "5144b0f151af40afa4e3758e74468ec6",
      "8f8b5cef50c44cd8a06c67baf8e8c8c2"
     ]
    },
    "colab_type": "code",
    "id": "5x5imMxOMts_",
    "outputId": "730c8e83-15b9-43e2-a549-51f43a860d56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b2-8bb594d6.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b2-8bb594d6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98aa2a8d041542c3855342e544915738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36804509.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b78fe2f88ea4c499a75ecfa8c5cd0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12550.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: torch.Size([3, 3, 256, 256]) | \n",
      " tensor([[0.0222, 0.9998, 0.0000],\n",
      "        [0.0000, 0.9939, 0.1104],\n",
      "        [0.0000, 0.9998, 0.0200]])\n",
      "Label: tensor([0., 0., 0.])\n",
      "Input Image Shape: torch.Size([3, 3, 256, 256]) \n",
      "Input csv_data shape: torch.Size([3, 3])\n",
      "Feature Image Shape: torch.Size([3, 1408, 8, 8])\n",
      "Image Reshaped Shape: torch.Size([3, 1408])\n",
      "CSV Data: torch.Size([3, 250])\n",
      "Out Shape: torch.Size([3, 1])\n",
      "Loss: 0.7744547724723816\n"
     ]
    }
   ],
   "source": [
    "eff_model = EfficientModel(output_size = output_size, no_columns = no_columns, net_type='b2')\n",
    "\n",
    "\n",
    "sample_loader = CustomLoader(train_df, is_train=True, is_test=False, is_valid=False).fetch(batch_size=3, num_workers=8)\n",
    "\n",
    "\n",
    "tk0 = tqdm(sample_loader, total=len(sample_loader))\n",
    "\n",
    "for data in sample_loader:\n",
    "    data_example = data[0]\n",
    "    labels_example = torch.tensor(data[1], dtype=torch.float32)\n",
    "    break\n",
    "\n",
    "print('Data Shape:', data_example[0].shape,'| \\n', data_example[1])\n",
    "print('Label:', labels_example)\n",
    "\n",
    "\n",
    "out = eff_model(data_example, prints=True)\n",
    "\n",
    "criterion_sample = nn.BCEWithLogitsLoss()\n",
    "\n",
    "loss = criterion_sample(out, labels_example.unsqueeze(1))\n",
    "\n",
    "print('Loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKFG5Yoo7Zt9"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "juz3XZivMttC",
    "outputId": "8656d59c-8660-4db9-a5f9-b5dcbf99dc1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof shape: (37648, 1) \n",
      "prediction shape: torch.Size([10982, 1])\n"
     ]
    }
   ],
   "source": [
    "train_len = len(train_df)\n",
    "test_len = len(test_df)\n",
    "\n",
    "oof = np.zeros(shape=(train_len, 1))\n",
    "\n",
    "preds_submission = torch.zeros(size = (test_len,1 ), dtype=torch.float32, device = device)\n",
    "\n",
    "print('oof shape:', oof.shape, '\\n' + \n",
    "     'prediction shape:', preds_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qdh7toPPMttG"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "patience = 3\n",
    "TTA = 3\n",
    "num_workers = 8\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 0.0\n",
    "lr_patience = 1\n",
    "\n",
    "lr_factor = 0.4\n",
    "\n",
    "batch_size1 = 16\n",
    "batch_size2 = 8\n",
    "\n",
    "version = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQbQ2BtAMttK"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    _xla_available = True\n",
    "except ImportError:\n",
    "    _xla_available = False\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "\n",
    "    _apex_available = True\n",
    "except ImportError:\n",
    "    _apex_available = False\n",
    "    \n",
    "\n",
    "\n",
    "def reduce_fn(vals):\n",
    "    return sum(vals) / len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zznau6wKMttR"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\" \n",
    "        Computes and stores the average\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-RwO3PiMttW"
   },
   "outputs": [],
   "source": [
    "class Engine:\n",
    "    \n",
    "    def __init__(self, model, optimizer, device, scheduler=None, print_step=None, use_tpu=False, fp16=False, print_metrics = 10):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.scheduler = scheduler\n",
    "        self.print_step = None\n",
    "        self.use_tpu = use_tpu\n",
    "        self.fp16 = fp16\n",
    "        self.accumulation_steps = 1\n",
    "        self.data_loader = None\n",
    "        self.print_metrics = print_metrics\n",
    "        if self.use_tpu and not _xla_available:\n",
    "            raise Exception(\n",
    "                \"pytorch_xla is not installed\"\n",
    "            )\n",
    "        if self.fp16 and not _apex_available:\n",
    "            raise Exception(\"fp16 needs Apex. Apex is not installed\")\n",
    "        if self.fp16 and use_tpu:\n",
    "            raise Exception(\"Apex fp16 is not available when using TPUs\")\n",
    "        if self.fp16:\n",
    "            self.accumulation_steps = 1\n",
    "  \n",
    "    def train(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "        losses = AverageMeter() # We need to use Average Loss from all the losses computed in TPU Cores\n",
    "        predictions = []\n",
    "        \n",
    "        self.model.train() #Initializing Model with Training Mode\n",
    "        \n",
    "        if self.accumulation_steps > 1:\n",
    "            optimizer.zero_grad()\n",
    "        if self.use_tpu:\n",
    "            para_loader = pl.ParallelLoader(self.data_loader, [self.device])\n",
    "            tloader = para_loader.per_device_loader(self.device) # TQDM Loader to monitor progress\n",
    "        else:\n",
    "            tloader = tqdm(self.data_loader, total= len(self.data_loader))\n",
    "        \n",
    "        for b_idx, data in enumerate(tloader):\n",
    "            \n",
    "            inputs = data[0]\n",
    "            \n",
    "            inputs = (inputs[0].to(self.device), inputs[1].to(self.device))\n",
    "            labels = data[1].to(self.device)\n",
    "            \n",
    "            if self.accumulation_steps == 1 and b_idx==0:\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            out = self.model(inputs)\n",
    "            \n",
    "            loss = nn.BCEWithLogitsLoss()(out, labels.view(-1, 1).type_as(out))\n",
    "            \n",
    "            if not self.use_tpu:\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    if fp16:\n",
    "                        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                            scaled_loss.backward()\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                    if (b_idx + 1) % self.accumulation_steps == 0:\n",
    "                        self.optimizer.step()\n",
    "                        if scheduler is not None:\n",
    "                            self.scheduler.step(loss)\n",
    "                        if b_idx > 0:\n",
    "                            self.optimizer.zero_grad()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                xm.optimizer_step(self.optimizer)\n",
    "                if self.scheduler is not None:\n",
    "                    self.scheduler.step(loss)\n",
    "                if b_idx > 0:\n",
    "                    self.optimizer.zero_grad()\n",
    "            if self.use_tpu:\n",
    "                reduced_loss = xm.mesh_reduce('loss_reduce', loss, reduce_fn)\n",
    "                losses.update(reduced_loss.item(), self.data_loader.batch_size)\n",
    "            else:\n",
    "                losses.update(loss.item(),self.data_loader.batch_size)\n",
    "            \n",
    "            if not self.use_tpu:\n",
    "                tloader.set_postfix(loss=losses.avg)\n",
    "            # else:\n",
    "            #     # if b_idx % self.print_metrics == 0 or b_idx == len(self.data_loader):\n",
    "            #     #     xm.master_print(\n",
    "            #     #         f\"{dt.datetime.now()}: Batch {b_idx} / {len(data_loader)}, loss={losses.avg}\"\n",
    "            #     #     )\n",
    "        if not self.use_tpu:\n",
    "            tloader.close()\n",
    "        return losses.avg\n",
    "    \n",
    "    \n",
    "    def evaluate(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "        losses = AverageMeter()\n",
    "        \n",
    "        final_predictions = []\n",
    "        final_targets = []\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.use_tpu:\n",
    "                para_loader = pl.ParallelLoader(self.data_loader, [self.device])\n",
    "                tloader = para_loader.per_device_loader(self.device)\n",
    "                              \n",
    "            else:\n",
    "                tloader = tqdm(self.dataloader, total=len(self.data_loader))\n",
    "            \n",
    "            for b_idx, data in enumerate(tloader):\n",
    "                \n",
    "                inputs = data[0]\n",
    "                labels = data[1].to(self.device)\n",
    "                \n",
    "                inputs = (inputs[0].to(self.device), inputs[1]. to(self.device))\n",
    "                \n",
    "                out = self.model(inputs)\n",
    "                \n",
    "                loss = nn.BCEWithLogitsLoss()(out, labels.view(-1, 1).type_as(out))\n",
    "                \n",
    "                if self.use_tpu:\n",
    "                    reduced_loss = xm.mesh_reduce('loss_reduce', loss, reduce_fn)\n",
    "                    losses.update(reduced_loss.item(), data_loader.batch_size)\n",
    "                    # if b_idx % self.print_metrics == 0 or b_idx == len(data_loader):\n",
    "                    #     xm.master_print(\n",
    "                    #         f\"{dt.datetime.now()}: Batch {b_idx} / {len(data_loader)}, loss={losses.avg}\")\n",
    "                else:\n",
    "                    losses.update(loss.item(), data_loader.batch_size)\n",
    "                    tloader.set_postfix(loss=losses.avg)\n",
    "                \n",
    "                \n",
    "            if not self.use_tpu:\n",
    "                tloader.close()\n",
    "                \n",
    "            return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Kx8xK3gFMttb",
    "outputId": "01459e30-3179-4feb-9ec8-ff56775f3268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    }
   ],
   "source": [
    "model_eff = EfficientModel(output_size = output_size, no_columns = no_columns, net_type='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8fezfR1Mtte"
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "group_fold = GroupKFold(n_splits = k)\n",
    "\n",
    "folds = group_fold.split(X= np.zeros(train_len),\n",
    "                        y = train_df['target'],\n",
    "                        groups= train_df['ID'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKH20WpDMtti"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs=15):\n",
    "    \n",
    "    device = xm.xla_device()\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    for fold, (train_indices, valid_indices) in enumerate(folds):\n",
    "        \n",
    "        xm.master_print('-'*10, f'Fold{fold}', '-'*10)\n",
    "    \n",
    "        train_data = train_df.iloc[train_indices].reset_index(drop=True)\n",
    "        valid_data = train_df.iloc[valid_indices].reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        train_loader = CustomLoader(train_data,\n",
    "                                    is_train=True,\n",
    "                                    is_valid=False,\n",
    "                                    is_test=False\n",
    "                                   ).fetch(batch_size=batch_size1,\n",
    "                                           drop_last=True,\n",
    "                                           tpu=True,\n",
    "                                           num_workers = 8,\n",
    "                                           shuffle=True      \n",
    "                                    )\n",
    "        valid_loader = CustomLoader(valid_data,\n",
    "                                   is_train=False,\n",
    "                                   is_valid=True,\n",
    "                                   is_test=False\n",
    "                                   ).fetch(batch_size=batch_size2,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=False,\n",
    "                                          tpu=True)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', \n",
    "                                      patience=lr_patience, verbose=True, factor=lr_factor)\n",
    "        \n",
    "        es = EarlyStopping(patience=3, mode='min', tpu=True)\n",
    "        \n",
    "        eng = Engine(model, optimizer, device, scheduler=None, print_step=None, use_tpu=True, fp16=False)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_loss = eng.train(data_loader = train_loader)\n",
    "            valid_loss = eng.evaluate(data_loader = valid_loader)\n",
    "            \n",
    "            xm.master_print(f\"Epoch ={epoch}| Train Loss = {train_loss} | Valid Loss={valid_loss}\")\n",
    "            scheduler.step(valid_loss)\n",
    "            \n",
    "            es(valid_loss, model, model_path=f'model_fold_{fold}.bin')\n",
    "            if es.early_stop:\n",
    "                xm.master_print('Early Stopping')\n",
    "                break\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrLjKmAGMttm"
   },
   "outputs": [],
   "source": [
    "def _mp_fn(rank, flags):\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    a = train_model(model_eff, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "4CMAbplNMtts",
    "outputId": "a67347eb-760c-4f69-b814-f0cea20a571f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Fold0 ----------\n",
      "Epoch =0| Train Loss = 0.253914315671641 | Valid Loss=0.1566062332745547\n",
      "Validation score improved (inf --> 0.1566062332745547). Saving model!\n",
      "Epoch =1| Train Loss = 0.21442217493847926 | Valid Loss=0.2533067571765124\n",
      "EarlyStopping counter: 1 out of 3\n"
     ]
    }
   ],
   "source": [
    "FLAGS = {}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbhfZIeD7l6G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "melanoma-classification-tpu-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11a0ea6cf3ed48d9a6c948490c2822c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fefdb48d75a47389e6bb6e6f4034437",
      "placeholder": "​",
      "style": "IPY_MODEL_19d07b0aa94c4a06a6cb9a2fc04db440",
      "value": " 35.1M/35.1M [00:06&lt;00:00, 5.98MB/s]"
     }
    },
    "19d07b0aa94c4a06a6cb9a2fc04db440": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d0da7ff8daa48a5bb8abc840eaba213": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3478c4a8631e4496a523e699b11cc3d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "43ad1b6892d24065baf27f89ba931a16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f8b5cef50c44cd8a06c67baf8e8c8c2",
      "placeholder": "​",
      "style": "IPY_MODEL_5144b0f151af40afa4e3758e74468ec6",
      "value": " 0/12550 [00:00&lt;?, ?it/s]"
     }
    },
    "4b78fe2f88ea4c499a75ecfa8c5cd0aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6a335bc975cc4e5f9cc5f307720900b9",
       "IPY_MODEL_43ad1b6892d24065baf27f89ba931a16"
      ],
      "layout": "IPY_MODEL_be0f0144424e497e8e4301a0a5a9d541"
     }
    },
    "5144b0f151af40afa4e3758e74468ec6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a335bc975cc4e5f9cc5f307720900b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e130e44a53304705a80ab7ec42cf0f0f",
      "max": 12550,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5a40e7df69a4915922c93f4e43e0cfb",
      "value": 0
     }
    },
    "8f8b5cef50c44cd8a06c67baf8e8c8c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98aa2a8d041542c3855342e544915738": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df009758bce245d88d569baa422a3023",
       "IPY_MODEL_11a0ea6cf3ed48d9a6c948490c2822c6"
      ],
      "layout": "IPY_MODEL_a46209433a4d42f786a3dde350d313eb"
     }
    },
    "9fefdb48d75a47389e6bb6e6f4034437": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a46209433a4d42f786a3dde350d313eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be0f0144424e497e8e4301a0a5a9d541": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df009758bce245d88d569baa422a3023": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d0da7ff8daa48a5bb8abc840eaba213",
      "max": 36804509,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3478c4a8631e4496a523e699b11cc3d0",
      "value": 36804509
     }
    },
    "e130e44a53304705a80ab7ec42cf0f0f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a40e7df69a4915922c93f4e43e0cfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
